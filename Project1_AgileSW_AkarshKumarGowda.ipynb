{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM61uEOfKvXc",
        "outputId": "95162512-aba9-4b42-fc1f-23dbc32f8465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DEEP LEARNING:"
      ],
      "metadata": {
        "id": "_ERK7zvsMEoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLASSIFICATION:"
      ],
      "metadata": {
        "id": "aNOlTTt9MOEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "x=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(500, activation='relu', input_dim=13))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train,y_train, epochs=100)\n",
        "print(model.predict(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPB9rk3P7q5X",
        "outputId": "aa087802-ccac-475b-b88d-23e307b478d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "24/24 [==============================] - 1s 3ms/step - loss: 1.4178 - accuracy: 0.6172\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7135\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.6823\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7682\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5379 - accuracy: 0.7370\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.7370\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7734\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7201\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7891\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3846 - accuracy: 0.8320\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7734\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7695\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8242\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3669 - accuracy: 0.8333\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8151\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8255\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8294\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7826\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7826\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8073\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8177\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8112\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7799\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8529\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8411\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3589 - accuracy: 0.8372\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8008\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.8216\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.7266\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7630\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7891\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3649 - accuracy: 0.8411\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8268\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3798 - accuracy: 0.8529\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8281\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8529\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3305 - accuracy: 0.8698\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8646\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8424\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8385\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8737\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8594\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3307 - accuracy: 0.8672\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8464\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8398\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3711 - accuracy: 0.8229\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8268\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8359\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8320\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3657 - accuracy: 0.8281\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3633 - accuracy: 0.8451\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8555\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3207 - accuracy: 0.8672\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8594\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8451\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8490\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8581\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8503\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3997 - accuracy: 0.8190\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.8607\n",
            "Epoch 61/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3255 - accuracy: 0.8763\n",
            "Epoch 62/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8633\n",
            "Epoch 63/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3501 - accuracy: 0.8516\n",
            "Epoch 64/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8672\n",
            "Epoch 65/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3654 - accuracy: 0.8464\n",
            "Epoch 66/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3097 - accuracy: 0.8737\n",
            "Epoch 67/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3068 - accuracy: 0.8763\n",
            "Epoch 68/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8672\n",
            "Epoch 69/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8568\n",
            "Epoch 70/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3229 - accuracy: 0.8685\n",
            "Epoch 71/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8737\n",
            "Epoch 72/100\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3116 - accuracy: 0.8698\n",
            "Epoch 73/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8724\n",
            "Epoch 74/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8333\n",
            "Epoch 75/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8490\n",
            "Epoch 76/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8477\n",
            "Epoch 77/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8659\n",
            "Epoch 78/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.8737\n",
            "Epoch 79/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8529\n",
            "Epoch 80/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8594\n",
            "Epoch 81/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8477\n",
            "Epoch 82/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8646\n",
            "Epoch 83/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8711\n",
            "Epoch 84/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8503\n",
            "Epoch 85/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3918 - accuracy: 0.8294\n",
            "Epoch 86/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2943 - accuracy: 0.8737\n",
            "Epoch 87/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8568\n",
            "Epoch 88/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3300 - accuracy: 0.8568\n",
            "Epoch 89/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8737\n",
            "Epoch 90/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8763\n",
            "Epoch 91/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8763\n",
            "Epoch 92/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8893\n",
            "Epoch 93/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8828\n",
            "Epoch 94/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8594\n",
            "Epoch 95/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8815\n",
            "Epoch 96/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8659\n",
            "Epoch 97/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8672\n",
            "Epoch 98/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8568\n",
            "Epoch 99/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8125\n",
            "Epoch 100/100\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8737\n",
            "9/9 [==============================] - 0s 2ms/step\n",
            "[[9.83816385e-01]\n",
            " [9.88263845e-01]\n",
            " [4.55939509e-02]\n",
            " [9.54573452e-01]\n",
            " [8.04315358e-02]\n",
            " [8.22545230e-01]\n",
            " [6.90117925e-02]\n",
            " [3.70076895e-02]\n",
            " [9.01100874e-01]\n",
            " [1.96778905e-02]\n",
            " [9.76187408e-01]\n",
            " [1.37768229e-02]\n",
            " [9.15032208e-01]\n",
            " [9.99999881e-01]\n",
            " [1.10432036e-01]\n",
            " [9.68305826e-01]\n",
            " [2.01028641e-02]\n",
            " [9.99976158e-01]\n",
            " [9.83976841e-01]\n",
            " [2.28489079e-02]\n",
            " [6.52848542e-01]\n",
            " [1.04198612e-01]\n",
            " [3.95193219e-01]\n",
            " [1.08534899e-02]\n",
            " [6.52848542e-01]\n",
            " [9.96688902e-01]\n",
            " [9.19283271e-01]\n",
            " [5.62670648e-01]\n",
            " [1.71318576e-02]\n",
            " [8.92077625e-01]\n",
            " [6.37799203e-01]\n",
            " [5.81165373e-01]\n",
            " [7.44439304e-01]\n",
            " [9.88263845e-01]\n",
            " [9.35931027e-01]\n",
            " [9.23483014e-01]\n",
            " [6.52848542e-01]\n",
            " [5.04893899e-01]\n",
            " [9.43538725e-01]\n",
            " [9.78974521e-01]\n",
            " [3.70076895e-02]\n",
            " [5.77955097e-02]\n",
            " [7.85007417e-01]\n",
            " [3.95193219e-01]\n",
            " [3.41806337e-02]\n",
            " [1.57749932e-02]\n",
            " [8.99188071e-02]\n",
            " [4.11101520e-01]\n",
            " [8.24427962e-01]\n",
            " [5.93334138e-01]\n",
            " [5.54032147e-01]\n",
            " [1.31617021e-02]\n",
            " [7.98377097e-01]\n",
            " [1.74682140e-02]\n",
            " [9.19283271e-01]\n",
            " [9.43538725e-01]\n",
            " [2.03790069e-01]\n",
            " [2.00256556e-02]\n",
            " [9.26658154e-01]\n",
            " [9.91156995e-01]\n",
            " [8.13594222e-01]\n",
            " [1.46442518e-01]\n",
            " [1.71318669e-02]\n",
            " [5.93334317e-01]\n",
            " [3.49603854e-02]\n",
            " [1.22134179e-01]\n",
            " [9.99826431e-01]\n",
            " [4.77601171e-01]\n",
            " [1.57749932e-02]\n",
            " [9.94505465e-01]\n",
            " [8.63613486e-01]\n",
            " [1.71318576e-02]\n",
            " [4.68938947e-01]\n",
            " [9.52359557e-01]\n",
            " [8.21974039e-01]\n",
            " [6.10439658e-01]\n",
            " [6.90117925e-02]\n",
            " [8.16206217e-01]\n",
            " [5.38824737e-01]\n",
            " [8.83305609e-01]\n",
            " [2.73607254e-01]\n",
            " [2.63611823e-01]\n",
            " [2.17627399e-02]\n",
            " [5.43228760e-02]\n",
            " [9.19364929e-01]\n",
            " [1.33544877e-02]\n",
            " [9.76187408e-01]\n",
            " [2.32075363e-01]\n",
            " [2.73607254e-01]\n",
            " [8.92077625e-01]\n",
            " [6.96529746e-01]\n",
            " [2.28489079e-02]\n",
            " [9.94841754e-01]\n",
            " [9.20957148e-01]\n",
            " [9.45452929e-01]\n",
            " [8.84007812e-01]\n",
            " [4.77601171e-01]\n",
            " [6.91867247e-02]\n",
            " [3.83667485e-03]\n",
            " [1.02146156e-01]\n",
            " [9.98685777e-01]\n",
            " [1.33191079e-01]\n",
            " [7.88815618e-01]\n",
            " [8.62245083e-01]\n",
            " [7.41919056e-02]\n",
            " [9.56637979e-01]\n",
            " [2.00256556e-02]\n",
            " [8.66783738e-01]\n",
            " [2.72753477e-01]\n",
            " [9.52875435e-01]\n",
            " [9.26658154e-01]\n",
            " [9.52875435e-01]\n",
            " [9.96542037e-01]\n",
            " [1.02058485e-01]\n",
            " [9.21728790e-01]\n",
            " [9.72709060e-01]\n",
            " [8.53206277e-01]\n",
            " [9.01722491e-01]\n",
            " [9.91467476e-01]\n",
            " [1.63664147e-02]\n",
            " [8.14568937e-01]\n",
            " [8.01991403e-01]\n",
            " [1.67408343e-02]\n",
            " [2.06135586e-01]\n",
            " [1.16488807e-01]\n",
            " [1.08534899e-02]\n",
            " [8.98134470e-01]\n",
            " [8.08097959e-01]\n",
            " [8.63613486e-01]\n",
            " [9.16051090e-01]\n",
            " [5.81165314e-01]\n",
            " [3.83667485e-03]\n",
            " [9.97033775e-01]\n",
            " [9.98685777e-01]\n",
            " [3.60946059e-02]\n",
            " [9.98874545e-01]\n",
            " [1.40631841e-02]\n",
            " [8.01991403e-01]\n",
            " [9.98874545e-01]\n",
            " [8.53206277e-01]\n",
            " [8.72670352e-01]\n",
            " [9.35800672e-01]\n",
            " [9.76728618e-01]\n",
            " [1.15511373e-01]\n",
            " [6.81839406e-01]\n",
            " [9.75574553e-01]\n",
            " [5.54032147e-01]\n",
            " [9.42646086e-01]\n",
            " [6.92550600e-01]\n",
            " [6.24863915e-02]\n",
            " [7.44439304e-01]\n",
            " [1.57749932e-02]\n",
            " [8.23907375e-01]\n",
            " [8.72670352e-01]\n",
            " [2.81318605e-01]\n",
            " [9.45068747e-02]\n",
            " [8.93159330e-01]\n",
            " [9.16051090e-01]\n",
            " [1.29904807e-01]\n",
            " [5.77954687e-02]\n",
            " [7.85007417e-01]\n",
            " [9.76894438e-01]\n",
            " [1.33191079e-01]\n",
            " [1.33191079e-01]\n",
            " [2.04141930e-01]\n",
            " [2.20795363e-01]\n",
            " [1.72750473e-01]\n",
            " [4.43818793e-02]\n",
            " [2.24046573e-01]\n",
            " [9.42646086e-01]\n",
            " [4.68938947e-01]\n",
            " [6.59260809e-01]\n",
            " [9.89359438e-01]\n",
            " [3.39803257e-04]\n",
            " [9.25542116e-01]\n",
            " [9.88263845e-01]\n",
            " [9.99740720e-01]\n",
            " [4.85526724e-03]\n",
            " [7.88815618e-01]\n",
            " [9.76714134e-01]\n",
            " [9.91676152e-01]\n",
            " [1.14840027e-02]\n",
            " [8.92487347e-01]\n",
            " [7.98377097e-01]\n",
            " [7.24978566e-01]\n",
            " [9.91467476e-01]\n",
            " [9.35931027e-01]\n",
            " [9.26658154e-01]\n",
            " [8.02189827e-01]\n",
            " [9.59985316e-01]\n",
            " [9.74308670e-01]\n",
            " [5.38824201e-01]\n",
            " [8.98745239e-01]\n",
            " [7.98377097e-01]\n",
            " [2.00256556e-02]\n",
            " [2.06910461e-01]\n",
            " [9.31004763e-01]\n",
            " [1.55679639e-02]\n",
            " [9.90384281e-01]\n",
            " [9.90084112e-01]\n",
            " [5.64700425e-01]\n",
            " [8.56627285e-01]\n",
            " [9.90084112e-01]\n",
            " [5.95565699e-02]\n",
            " [4.55442965e-01]\n",
            " [1.99179187e-01]\n",
            " [6.53187335e-01]\n",
            " [9.89675283e-01]\n",
            " [6.86198950e-01]\n",
            " [8.01991403e-01]\n",
            " [8.56627285e-01]\n",
            " [1.58187255e-01]\n",
            " [9.99895871e-01]\n",
            " [6.96529746e-01]\n",
            " [9.45068747e-02]\n",
            " [1.94570079e-01]\n",
            " [6.07954621e-01]\n",
            " [1.72750473e-01]\n",
            " [7.07490861e-01]\n",
            " [3.60946059e-02]\n",
            " [7.76385307e-01]\n",
            " [2.17627399e-02]\n",
            " [1.02146335e-01]\n",
            " [9.85164642e-01]\n",
            " [9.27116096e-01]\n",
            " [8.34412992e-01]\n",
            " [9.01722491e-01]\n",
            " [7.06708193e-01]\n",
            " [1.37768229e-02]\n",
            " [8.14568937e-01]\n",
            " [8.98745239e-01]\n",
            " [4.94324893e-01]\n",
            " [7.88855791e-01]\n",
            " [8.93159330e-01]\n",
            " [6.24863915e-02]\n",
            " [6.90117925e-02]\n",
            " [2.97181964e-01]\n",
            " [2.19697952e-01]\n",
            " [9.75116670e-01]\n",
            " [6.33928359e-01]\n",
            " [4.71251577e-01]\n",
            " [5.21852255e-01]\n",
            " [9.99985099e-01]\n",
            " [1.63045824e-01]\n",
            " [2.98824906e-02]\n",
            " [8.66783738e-01]\n",
            " [9.19536501e-02]\n",
            " [9.98685777e-01]\n",
            " [8.83974314e-01]\n",
            " [1.39316335e-01]\n",
            " [9.52359557e-01]\n",
            " [1.96778905e-02]\n",
            " [5.12983799e-01]\n",
            " [4.85526724e-03]\n",
            " [2.06135437e-01]\n",
            " [9.93538618e-01]\n",
            " [8.49572942e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "x=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, activation='relu', input_dim=13))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train,y_train, epochs=200)\n",
        "print(model.predict(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUc9KDGJMELx",
        "outputId": "e3f08f59-9f72-481f-9b06-410c35549966"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "24/24 [==============================] - 4s 23ms/step - loss: 1.5483 - accuracy: 0.5599\n",
            "Epoch 2/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7401 - accuracy: 0.6419\n",
            "Epoch 3/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.6081 - accuracy: 0.6680\n",
            "Epoch 4/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6423 - accuracy: 0.6758\n",
            "Epoch 5/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.7318 - accuracy: 0.6432\n",
            "Epoch 6/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5725 - accuracy: 0.7148\n",
            "Epoch 7/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5643 - accuracy: 0.7018\n",
            "Epoch 8/200\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.5689 - accuracy: 0.7161\n",
            "Epoch 9/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4834 - accuracy: 0.7682\n",
            "Epoch 10/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4635 - accuracy: 0.7826\n",
            "Epoch 11/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4620 - accuracy: 0.7682\n",
            "Epoch 12/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.7839\n",
            "Epoch 13/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.4361 - accuracy: 0.7969\n",
            "Epoch 14/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4115 - accuracy: 0.8242\n",
            "Epoch 15/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4338 - accuracy: 0.7930\n",
            "Epoch 16/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3789 - accuracy: 0.8385\n",
            "Epoch 17/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4151 - accuracy: 0.8164\n",
            "Epoch 18/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4044 - accuracy: 0.8203\n",
            "Epoch 19/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4744 - accuracy: 0.7799\n",
            "Epoch 20/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4217 - accuracy: 0.8138\n",
            "Epoch 21/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.4786 - accuracy: 0.7852\n",
            "Epoch 22/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3906 - accuracy: 0.8359\n",
            "Epoch 23/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3870 - accuracy: 0.8294\n",
            "Epoch 24/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3867 - accuracy: 0.8268\n",
            "Epoch 25/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3713 - accuracy: 0.8568\n",
            "Epoch 26/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4401 - accuracy: 0.8060\n",
            "Epoch 27/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3890 - accuracy: 0.8438\n",
            "Epoch 28/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.4017 - accuracy: 0.8151\n",
            "Epoch 29/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3662 - accuracy: 0.8477\n",
            "Epoch 30/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3915 - accuracy: 0.8151\n",
            "Epoch 31/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.3864 - accuracy: 0.8099\n",
            "Epoch 32/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.4865 - accuracy: 0.7734\n",
            "Epoch 33/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3868 - accuracy: 0.8242\n",
            "Epoch 34/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3492 - accuracy: 0.8385\n",
            "Epoch 35/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3531 - accuracy: 0.8385\n",
            "Epoch 36/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3501 - accuracy: 0.8464\n",
            "Epoch 37/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3499 - accuracy: 0.8529\n",
            "Epoch 38/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3323 - accuracy: 0.8633\n",
            "Epoch 39/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3917 - accuracy: 0.8268\n",
            "Epoch 40/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3648 - accuracy: 0.8477\n",
            "Epoch 41/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3736 - accuracy: 0.8385\n",
            "Epoch 42/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.4279 - accuracy: 0.7969\n",
            "Epoch 43/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3618 - accuracy: 0.8320\n",
            "Epoch 44/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3436 - accuracy: 0.8464\n",
            "Epoch 45/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3329 - accuracy: 0.8646\n",
            "Epoch 46/200\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.3319 - accuracy: 0.8568\n",
            "Epoch 47/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3447 - accuracy: 0.8477\n",
            "Epoch 48/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3146 - accuracy: 0.8646\n",
            "Epoch 49/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3286 - accuracy: 0.8607\n",
            "Epoch 50/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3259 - accuracy: 0.8581\n",
            "Epoch 51/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3319 - accuracy: 0.8555\n",
            "Epoch 52/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3278 - accuracy: 0.8711\n",
            "Epoch 53/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3137 - accuracy: 0.8633\n",
            "Epoch 54/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3883 - accuracy: 0.8281\n",
            "Epoch 55/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3793 - accuracy: 0.8372\n",
            "Epoch 56/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3807 - accuracy: 0.8164\n",
            "Epoch 57/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3337 - accuracy: 0.8451\n",
            "Epoch 58/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3287 - accuracy: 0.8646\n",
            "Epoch 59/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3244 - accuracy: 0.8503\n",
            "Epoch 60/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.3115 - accuracy: 0.8698\n",
            "Epoch 61/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3215 - accuracy: 0.8581\n",
            "Epoch 62/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.8464\n",
            "Epoch 63/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3061 - accuracy: 0.8698\n",
            "Epoch 64/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3378 - accuracy: 0.8594\n",
            "Epoch 65/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3166 - accuracy: 0.8685\n",
            "Epoch 66/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3176 - accuracy: 0.8620\n",
            "Epoch 67/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2920 - accuracy: 0.8763\n",
            "Epoch 68/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2999 - accuracy: 0.8724\n",
            "Epoch 69/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3195 - accuracy: 0.8594\n",
            "Epoch 70/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3203 - accuracy: 0.8724\n",
            "Epoch 71/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3076 - accuracy: 0.8737\n",
            "Epoch 72/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3022 - accuracy: 0.8724\n",
            "Epoch 73/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3256 - accuracy: 0.8672\n",
            "Epoch 74/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3695 - accuracy: 0.8320\n",
            "Epoch 75/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3865 - accuracy: 0.8151\n",
            "Epoch 76/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3479 - accuracy: 0.8516\n",
            "Epoch 77/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3055 - accuracy: 0.8685\n",
            "Epoch 78/200\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.3072 - accuracy: 0.8750\n",
            "Epoch 79/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3020 - accuracy: 0.8828\n",
            "Epoch 80/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3103 - accuracy: 0.8724\n",
            "Epoch 81/200\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.3115 - accuracy: 0.8607\n",
            "Epoch 82/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2962 - accuracy: 0.8776\n",
            "Epoch 83/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.8620\n",
            "Epoch 84/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3059 - accuracy: 0.8776\n",
            "Epoch 85/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3023 - accuracy: 0.8724\n",
            "Epoch 86/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3017 - accuracy: 0.8711\n",
            "Epoch 87/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2845 - accuracy: 0.8789\n",
            "Epoch 88/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2900 - accuracy: 0.8802\n",
            "Epoch 89/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3071 - accuracy: 0.8672\n",
            "Epoch 90/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2886 - accuracy: 0.8776\n",
            "Epoch 91/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2917 - accuracy: 0.8789\n",
            "Epoch 92/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3019 - accuracy: 0.8633\n",
            "Epoch 93/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2993 - accuracy: 0.8711\n",
            "Epoch 94/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2785 - accuracy: 0.8893\n",
            "Epoch 95/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3064 - accuracy: 0.8724\n",
            "Epoch 96/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2938 - accuracy: 0.8711\n",
            "Epoch 97/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2882 - accuracy: 0.8815\n",
            "Epoch 98/200\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.3240 - accuracy: 0.8581\n",
            "Epoch 99/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3581 - accuracy: 0.8503\n",
            "Epoch 100/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2928 - accuracy: 0.8711\n",
            "Epoch 101/200\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.2854 - accuracy: 0.8802\n",
            "Epoch 102/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2702 - accuracy: 0.8880\n",
            "Epoch 103/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2640 - accuracy: 0.8841\n",
            "Epoch 104/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.2979 - accuracy: 0.8698\n",
            "Epoch 105/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3618 - accuracy: 0.8255\n",
            "Epoch 106/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2799 - accuracy: 0.8828\n",
            "Epoch 107/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2718 - accuracy: 0.8841\n",
            "Epoch 108/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3157 - accuracy: 0.8581\n",
            "Epoch 109/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2778 - accuracy: 0.8750\n",
            "Epoch 110/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2578 - accuracy: 0.8802\n",
            "Epoch 111/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2630 - accuracy: 0.8893\n",
            "Epoch 112/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2803 - accuracy: 0.8659\n",
            "Epoch 113/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2705 - accuracy: 0.8906\n",
            "Epoch 114/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2980 - accuracy: 0.8620\n",
            "Epoch 115/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2847 - accuracy: 0.8672\n",
            "Epoch 116/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2620 - accuracy: 0.8854\n",
            "Epoch 117/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2476 - accuracy: 0.8984\n",
            "Epoch 118/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2603 - accuracy: 0.8880\n",
            "Epoch 119/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2575 - accuracy: 0.8945\n",
            "Epoch 120/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2795 - accuracy: 0.8776\n",
            "Epoch 121/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2476 - accuracy: 0.8971\n",
            "Epoch 122/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2386 - accuracy: 0.8945\n",
            "Epoch 123/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2408 - accuracy: 0.9010\n",
            "Epoch 124/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2435 - accuracy: 0.9023\n",
            "Epoch 125/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2962 - accuracy: 0.8672\n",
            "Epoch 126/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.2616 - accuracy: 0.8802\n",
            "Epoch 127/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.2328 - accuracy: 0.8984\n",
            "Epoch 128/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2415 - accuracy: 0.8958\n",
            "Epoch 129/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2551 - accuracy: 0.8828\n",
            "Epoch 130/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2390 - accuracy: 0.8919\n",
            "Epoch 131/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3220 - accuracy: 0.8477\n",
            "Epoch 132/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3014 - accuracy: 0.8698\n",
            "Epoch 133/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2693 - accuracy: 0.8919\n",
            "Epoch 134/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.3265 - accuracy: 0.8529\n",
            "Epoch 135/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 0.8828\n",
            "Epoch 136/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.8763\n",
            "Epoch 137/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2435 - accuracy: 0.8906\n",
            "Epoch 138/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2316 - accuracy: 0.8958\n",
            "Epoch 139/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2595 - accuracy: 0.8906\n",
            "Epoch 140/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2457 - accuracy: 0.8958\n",
            "Epoch 141/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3321 - accuracy: 0.8711\n",
            "Epoch 142/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.3190 - accuracy: 0.8737\n",
            "Epoch 143/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2728 - accuracy: 0.8880\n",
            "Epoch 144/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2612 - accuracy: 0.8841\n",
            "Epoch 145/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2584 - accuracy: 0.9010\n",
            "Epoch 146/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2737 - accuracy: 0.8724\n",
            "Epoch 147/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2495 - accuracy: 0.8984\n",
            "Epoch 148/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2458 - accuracy: 0.8919\n",
            "Epoch 149/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2389 - accuracy: 0.8971\n",
            "Epoch 150/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2367 - accuracy: 0.8880\n",
            "Epoch 151/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2448 - accuracy: 0.8906\n",
            "Epoch 152/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3341 - accuracy: 0.8477\n",
            "Epoch 153/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2538 - accuracy: 0.8711\n",
            "Epoch 154/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2274 - accuracy: 0.8958\n",
            "Epoch 155/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2272 - accuracy: 0.8880\n",
            "Epoch 156/200\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.2325 - accuracy: 0.8958\n",
            "Epoch 157/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.2242 - accuracy: 0.9036\n",
            "Epoch 158/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2088 - accuracy: 0.9089\n",
            "Epoch 159/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2198 - accuracy: 0.9049\n",
            "Epoch 160/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2472 - accuracy: 0.8919\n",
            "Epoch 161/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2006 - accuracy: 0.9193\n",
            "Epoch 162/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2136 - accuracy: 0.9049\n",
            "Epoch 163/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.1844 - accuracy: 0.9206\n",
            "Epoch 164/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1773 - accuracy: 0.9336\n",
            "Epoch 165/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1853 - accuracy: 0.9219\n",
            "Epoch 166/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2371 - accuracy: 0.8971\n",
            "Epoch 167/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1956 - accuracy: 0.9206\n",
            "Epoch 168/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2343 - accuracy: 0.8893\n",
            "Epoch 169/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.2374 - accuracy: 0.8945\n",
            "Epoch 170/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2430 - accuracy: 0.8919\n",
            "Epoch 171/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2419 - accuracy: 0.9036\n",
            "Epoch 172/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3242 - accuracy: 0.8516\n",
            "Epoch 173/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2498 - accuracy: 0.8880\n",
            "Epoch 174/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2089 - accuracy: 0.9141\n",
            "Epoch 175/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2015 - accuracy: 0.9115\n",
            "Epoch 176/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2273 - accuracy: 0.9023\n",
            "Epoch 177/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2205 - accuracy: 0.8971\n",
            "Epoch 178/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1914 - accuracy: 0.9206\n",
            "Epoch 179/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1716 - accuracy: 0.9232\n",
            "Epoch 180/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1757 - accuracy: 0.9310\n",
            "Epoch 181/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1575 - accuracy: 0.9336\n",
            "Epoch 182/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 0.9336\n",
            "Epoch 183/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1534 - accuracy: 0.9349\n",
            "Epoch 184/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1874 - accuracy: 0.9206\n",
            "Epoch 185/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1781 - accuracy: 0.9349\n",
            "Epoch 186/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1497 - accuracy: 0.9440\n",
            "Epoch 187/200\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.1589 - accuracy: 0.9427\n",
            "Epoch 188/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1283 - accuracy: 0.9505\n",
            "Epoch 189/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1200 - accuracy: 0.9531\n",
            "Epoch 190/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1638 - accuracy: 0.9323\n",
            "Epoch 191/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1473 - accuracy: 0.9310\n",
            "Epoch 192/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1890 - accuracy: 0.9102\n",
            "Epoch 193/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1856 - accuracy: 0.9180\n",
            "Epoch 194/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1439 - accuracy: 0.9453\n",
            "Epoch 195/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.1532 - accuracy: 0.9349\n",
            "Epoch 196/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2583 - accuracy: 0.8815\n",
            "Epoch 197/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1902 - accuracy: 0.9115\n",
            "Epoch 198/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1250 - accuracy: 0.9531\n",
            "Epoch 199/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.1067 - accuracy: 0.9635\n",
            "Epoch 200/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.0942 - accuracy: 0.9635\n",
            "9/9 [==============================] - 0s 4ms/step\n",
            "[[9.78087902e-01]\n",
            " [1.00000000e+00]\n",
            " [1.46034949e-06]\n",
            " [9.61329103e-01]\n",
            " [1.65624754e-03]\n",
            " [9.99457777e-01]\n",
            " [3.09039402e-04]\n",
            " [4.01748330e-05]\n",
            " [9.67666566e-01]\n",
            " [2.10990622e-14]\n",
            " [8.74182105e-01]\n",
            " [1.94598346e-08]\n",
            " [9.86270010e-01]\n",
            " [1.00000000e+00]\n",
            " [1.47316443e-08]\n",
            " [8.96388888e-01]\n",
            " [2.28239924e-06]\n",
            " [1.00000000e+00]\n",
            " [1.00000000e+00]\n",
            " [2.94074107e-06]\n",
            " [7.70075560e-01]\n",
            " [5.47560398e-04]\n",
            " [1.90437689e-01]\n",
            " [1.74739334e-10]\n",
            " [7.70075560e-01]\n",
            " [1.00000000e+00]\n",
            " [9.87782300e-01]\n",
            " [9.80964005e-01]\n",
            " [2.57733632e-07]\n",
            " [9.24101174e-01]\n",
            " [8.24259147e-02]\n",
            " [8.18790436e-01]\n",
            " [1.79785460e-01]\n",
            " [1.00000000e+00]\n",
            " [9.71657872e-01]\n",
            " [8.89723361e-01]\n",
            " [7.70075560e-01]\n",
            " [6.58431053e-01]\n",
            " [9.65190828e-01]\n",
            " [9.92018163e-01]\n",
            " [4.01748330e-05]\n",
            " [1.26538460e-08]\n",
            " [8.37381721e-01]\n",
            " [1.90437689e-01]\n",
            " [6.58865866e-14]\n",
            " [3.31201143e-11]\n",
            " [1.30875589e-04]\n",
            " [5.76677965e-03]\n",
            " [7.76139146e-04]\n",
            " [5.28009117e-01]\n",
            " [6.98352396e-01]\n",
            " [5.39626370e-08]\n",
            " [1.70071959e-01]\n",
            " [1.26128979e-13]\n",
            " [9.87782300e-01]\n",
            " [9.65190828e-01]\n",
            " [1.25940144e-03]\n",
            " [2.29105970e-10]\n",
            " [3.04255456e-01]\n",
            " [9.99980688e-01]\n",
            " [8.99250686e-01]\n",
            " [9.92575288e-01]\n",
            " [2.57732637e-07]\n",
            " [5.28008997e-01]\n",
            " [1.93874475e-05]\n",
            " [4.91131154e-08]\n",
            " [9.99999821e-01]\n",
            " [2.02338591e-01]\n",
            " [3.31201143e-11]\n",
            " [9.99981284e-01]\n",
            " [8.01216811e-03]\n",
            " [2.57733632e-07]\n",
            " [4.06868567e-05]\n",
            " [9.81037974e-01]\n",
            " [9.53347683e-01]\n",
            " [6.03947937e-01]\n",
            " [3.09039402e-04]\n",
            " [2.08772588e-04]\n",
            " [3.41226369e-01]\n",
            " [9.76285517e-01]\n",
            " [1.86935428e-03]\n",
            " [4.38508829e-09]\n",
            " [2.58173969e-07]\n",
            " [6.36843197e-07]\n",
            " [9.99576211e-01]\n",
            " [1.95734717e-09]\n",
            " [8.74182105e-01]\n",
            " [1.20275914e-07]\n",
            " [1.86935428e-03]\n",
            " [9.24101174e-01]\n",
            " [1.34564042e-01]\n",
            " [2.94074107e-06]\n",
            " [1.00000000e+00]\n",
            " [9.66153145e-01]\n",
            " [9.74345207e-01]\n",
            " [8.47401559e-01]\n",
            " [2.02338591e-01]\n",
            " [8.26819232e-05]\n",
            " [1.65460134e-13]\n",
            " [1.49041720e-04]\n",
            " [1.00000000e+00]\n",
            " [2.27631360e-01]\n",
            " [5.87639213e-01]\n",
            " [9.19428051e-01]\n",
            " [3.84666663e-07]\n",
            " [9.99999344e-01]\n",
            " [2.29105970e-10]\n",
            " [9.98460829e-01]\n",
            " [8.18225462e-03]\n",
            " [9.99756217e-01]\n",
            " [3.04255456e-01]\n",
            " [9.99756217e-01]\n",
            " [9.99998748e-01]\n",
            " [1.84571487e-04]\n",
            " [9.99269724e-01]\n",
            " [9.99995232e-01]\n",
            " [7.64193594e-01]\n",
            " [9.74728346e-01]\n",
            " [8.81044745e-01]\n",
            " [3.26364891e-08]\n",
            " [9.90813375e-01]\n",
            " [9.59320664e-01]\n",
            " [3.17020382e-10]\n",
            " [6.81030145e-03]\n",
            " [9.49713588e-01]\n",
            " [1.74739334e-10]\n",
            " [9.93544519e-01]\n",
            " [2.32506404e-03]\n",
            " [8.01216811e-03]\n",
            " [9.65259552e-01]\n",
            " [8.18790793e-01]\n",
            " [1.65460134e-13]\n",
            " [9.99573231e-01]\n",
            " [1.00000000e+00]\n",
            " [7.99795430e-07]\n",
            " [1.00000000e+00]\n",
            " [4.28001167e-13]\n",
            " [9.59320664e-01]\n",
            " [1.00000000e+00]\n",
            " [7.64193594e-01]\n",
            " [8.81301761e-01]\n",
            " [9.59089339e-01]\n",
            " [9.93957102e-01]\n",
            " [6.83475614e-01]\n",
            " [8.95300031e-01]\n",
            " [9.76163805e-01]\n",
            " [6.98352396e-01]\n",
            " [9.85054910e-01]\n",
            " [2.99816459e-01]\n",
            " [5.47903142e-07]\n",
            " [1.79785460e-01]\n",
            " [3.31201143e-11]\n",
            " [8.78710389e-01]\n",
            " [8.81301761e-01]\n",
            " [1.84872337e-02]\n",
            " [2.44715542e-04]\n",
            " [5.04717946e-01]\n",
            " [9.65259552e-01]\n",
            " [9.25079235e-10]\n",
            " [1.26539179e-08]\n",
            " [8.37381721e-01]\n",
            " [9.99999881e-01]\n",
            " [2.27631360e-01]\n",
            " [2.27631360e-01]\n",
            " [8.42398584e-01]\n",
            " [8.23928535e-01]\n",
            " [2.45505432e-03]\n",
            " [3.22489323e-05]\n",
            " [7.33037591e-01]\n",
            " [9.85054910e-01]\n",
            " [4.06868567e-05]\n",
            " [9.42437530e-01]\n",
            " [1.00000000e+00]\n",
            " [1.31307316e-28]\n",
            " [8.45588505e-01]\n",
            " [1.00000000e+00]\n",
            " [1.00000000e+00]\n",
            " [1.77455359e-12]\n",
            " [5.87639213e-01]\n",
            " [9.97356057e-01]\n",
            " [9.99996006e-01]\n",
            " [4.97570363e-05]\n",
            " [9.89927769e-01]\n",
            " [1.70071959e-01]\n",
            " [5.65875471e-01]\n",
            " [8.81044745e-01]\n",
            " [9.71657872e-01]\n",
            " [3.04255456e-01]\n",
            " [7.89745986e-01]\n",
            " [9.99991119e-01]\n",
            " [9.98601973e-01]\n",
            " [3.41226310e-01]\n",
            " [1.01572815e-02]\n",
            " [1.70071959e-01]\n",
            " [2.29105970e-10]\n",
            " [9.35770810e-01]\n",
            " [8.71030927e-01]\n",
            " [1.74671402e-06]\n",
            " [9.97442663e-01]\n",
            " [9.99549448e-01]\n",
            " [6.19063377e-01]\n",
            " [9.96296346e-01]\n",
            " [9.99549448e-01]\n",
            " [3.29536509e-10]\n",
            " [6.28383160e-02]\n",
            " [1.25135884e-07]\n",
            " [8.93382609e-01]\n",
            " [9.32567656e-01]\n",
            " [2.91663259e-01]\n",
            " [9.59320664e-01]\n",
            " [9.96296346e-01]\n",
            " [9.86022860e-05]\n",
            " [1.00000000e+00]\n",
            " [1.34564042e-01]\n",
            " [2.44715542e-04]\n",
            " [2.55189661e-05]\n",
            " [5.91396354e-02]\n",
            " [2.45505432e-03]\n",
            " [8.62977207e-01]\n",
            " [7.99795430e-07]\n",
            " [8.38681638e-01]\n",
            " [2.58173969e-07]\n",
            " [1.49042011e-04]\n",
            " [9.96661186e-01]\n",
            " [9.81837869e-01]\n",
            " [9.27104533e-01]\n",
            " [9.74728346e-01]\n",
            " [8.54359448e-01]\n",
            " [1.94598346e-08]\n",
            " [9.90813375e-01]\n",
            " [1.01572815e-02]\n",
            " [7.33874589e-02]\n",
            " [8.52543712e-02]\n",
            " [5.04717946e-01]\n",
            " [5.47903142e-07]\n",
            " [3.09039402e-04]\n",
            " [4.14546467e-02]\n",
            " [4.92356624e-03]\n",
            " [9.69268680e-01]\n",
            " [2.01707790e-05]\n",
            " [2.81824589e-01]\n",
            " [1.44329399e-01]\n",
            " [1.00000000e+00]\n",
            " [1.57323352e-03]\n",
            " [2.00499994e-06]\n",
            " [9.98460829e-01]\n",
            " [1.07886940e-02]\n",
            " [1.00000000e+00]\n",
            " [9.99718487e-01]\n",
            " [1.04666613e-02]\n",
            " [9.81037974e-01]\n",
            " [2.10990622e-14]\n",
            " [6.17549896e-01]\n",
            " [1.77455359e-12]\n",
            " [6.81030797e-03]\n",
            " [1.00000000e+00]\n",
            " [2.09269345e-07]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Import necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Keras specific\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "x=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, activation='relu', input_dim=13))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train,y_train, epochs=200)\n",
        "print(model.predict(x_test))"
      ],
      "metadata": {
        "id": "vVIVI5eG7TBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da5a849-e628-4fdc-edbd-0866fbfe0771"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "24/24 [==============================] - 4s 17ms/step - loss: 2.2049 - accuracy: 0.5573\n",
            "Epoch 2/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.8437 - accuracy: 0.6237\n",
            "Epoch 3/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.7695 - accuracy: 0.6419\n",
            "Epoch 4/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.5781 - accuracy: 0.6784\n",
            "Epoch 5/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6201 - accuracy: 0.6849\n",
            "Epoch 6/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.6163 - accuracy: 0.6862\n",
            "Epoch 7/200\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.7130 - accuracy: 0.6510\n",
            "Epoch 8/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.5521 - accuracy: 0.7214\n",
            "Epoch 9/200\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.5071 - accuracy: 0.7383\n",
            "Epoch 10/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.4868 - accuracy: 0.7643\n",
            "Epoch 11/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.4564 - accuracy: 0.7826\n",
            "Epoch 12/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.5605 - accuracy: 0.7292\n",
            "Epoch 13/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.4594 - accuracy: 0.7786\n",
            "Epoch 14/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.4265 - accuracy: 0.7969\n",
            "Epoch 15/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.8125\n",
            "Epoch 16/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3816 - accuracy: 0.8503\n",
            "Epoch 17/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.4147 - accuracy: 0.7995\n",
            "Epoch 18/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.7865\n",
            "Epoch 19/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3639 - accuracy: 0.8451\n",
            "Epoch 20/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.4157 - accuracy: 0.7943\n",
            "Epoch 21/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3772 - accuracy: 0.8281\n",
            "Epoch 22/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3457 - accuracy: 0.8698\n",
            "Epoch 23/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3903 - accuracy: 0.8424\n",
            "Epoch 24/200\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.3532 - accuracy: 0.8529\n",
            "Epoch 25/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3991 - accuracy: 0.8203\n",
            "Epoch 26/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3819 - accuracy: 0.8346\n",
            "Epoch 27/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3815 - accuracy: 0.8411\n",
            "Epoch 28/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3875 - accuracy: 0.8451\n",
            "Epoch 29/200\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.4653 - accuracy: 0.8021\n",
            "Epoch 30/200\n",
            "24/24 [==============================] - 1s 28ms/step - loss: 0.4817 - accuracy: 0.7812\n",
            "Epoch 31/200\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.3448 - accuracy: 0.8581\n",
            "Epoch 32/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3452 - accuracy: 0.8490\n",
            "Epoch 33/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3364 - accuracy: 0.8698\n",
            "Epoch 34/200\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.3579 - accuracy: 0.8477\n",
            "Epoch 35/200\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.3595 - accuracy: 0.8359\n",
            "Epoch 36/200\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.4562 - accuracy: 0.7904\n",
            "Epoch 37/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4086 - accuracy: 0.8138\n",
            "Epoch 38/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3784 - accuracy: 0.8242\n",
            "Epoch 39/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3892 - accuracy: 0.8164\n",
            "Epoch 40/200\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.3556 - accuracy: 0.8320\n",
            "Epoch 41/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3498 - accuracy: 0.8464\n",
            "Epoch 42/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3688 - accuracy: 0.8424\n",
            "Epoch 43/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3408 - accuracy: 0.8503\n",
            "Epoch 44/200\n",
            "24/24 [==============================] - 0s 13ms/step - loss: 0.3511 - accuracy: 0.8385\n",
            "Epoch 45/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3531 - accuracy: 0.8581\n",
            "Epoch 46/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3736 - accuracy: 0.8203\n",
            "Epoch 47/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3593 - accuracy: 0.8490\n",
            "Epoch 48/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3644 - accuracy: 0.8464\n",
            "Epoch 49/200\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.3233 - accuracy: 0.8776\n",
            "Epoch 50/200\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.3225 - accuracy: 0.8672\n",
            "Epoch 51/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3270 - accuracy: 0.8646\n",
            "Epoch 52/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.3188 - accuracy: 0.8685\n",
            "Epoch 53/200\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.3149 - accuracy: 0.8737\n",
            "Epoch 54/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3174 - accuracy: 0.8698\n",
            "Epoch 55/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3158 - accuracy: 0.8542\n",
            "Epoch 56/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3282 - accuracy: 0.8529\n",
            "Epoch 57/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3315 - accuracy: 0.8724\n",
            "Epoch 58/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3330 - accuracy: 0.8529\n",
            "Epoch 59/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3376 - accuracy: 0.8607\n",
            "Epoch 60/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3153 - accuracy: 0.8646\n",
            "Epoch 61/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3264 - accuracy: 0.8659\n",
            "Epoch 62/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3155 - accuracy: 0.8698\n",
            "Epoch 63/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3281 - accuracy: 0.8672\n",
            "Epoch 64/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.3240 - accuracy: 0.8555\n",
            "Epoch 65/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3296 - accuracy: 0.8594\n",
            "Epoch 66/200\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.3455 - accuracy: 0.8464\n",
            "Epoch 67/200\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.3142 - accuracy: 0.8698\n",
            "Epoch 68/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.3028 - accuracy: 0.8841\n",
            "Epoch 69/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3120 - accuracy: 0.8685\n",
            "Epoch 70/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3102 - accuracy: 0.8724\n",
            "Epoch 71/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2925 - accuracy: 0.8750\n",
            "Epoch 72/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3036 - accuracy: 0.8737\n",
            "Epoch 73/200\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.3201 - accuracy: 0.8620\n",
            "Epoch 74/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.3181 - accuracy: 0.8659\n",
            "Epoch 75/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2987 - accuracy: 0.8750\n",
            "Epoch 76/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3233 - accuracy: 0.8503\n",
            "Epoch 77/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2999 - accuracy: 0.8802\n",
            "Epoch 78/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3030 - accuracy: 0.8672\n",
            "Epoch 79/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.3063 - accuracy: 0.8776\n",
            "Epoch 80/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2937 - accuracy: 0.8685\n",
            "Epoch 81/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3454 - accuracy: 0.8464\n",
            "Epoch 82/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3039 - accuracy: 0.8711\n",
            "Epoch 83/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2929 - accuracy: 0.8685\n",
            "Epoch 84/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3013 - accuracy: 0.8724\n",
            "Epoch 85/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3245 - accuracy: 0.8607\n",
            "Epoch 86/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3009 - accuracy: 0.8724\n",
            "Epoch 87/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3597 - accuracy: 0.8333\n",
            "Epoch 88/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3555 - accuracy: 0.8594\n",
            "Epoch 89/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3215 - accuracy: 0.8672\n",
            "Epoch 90/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2874 - accuracy: 0.8854\n",
            "Epoch 91/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2970 - accuracy: 0.8815\n",
            "Epoch 92/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3188 - accuracy: 0.8568\n",
            "Epoch 93/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2873 - accuracy: 0.8763\n",
            "Epoch 94/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2955 - accuracy: 0.8737\n",
            "Epoch 95/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 0.8802\n",
            "Epoch 96/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2803 - accuracy: 0.8854\n",
            "Epoch 97/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2753 - accuracy: 0.8867\n",
            "Epoch 98/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3706 - accuracy: 0.8438\n",
            "Epoch 99/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.4352 - accuracy: 0.8138\n",
            "Epoch 100/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3462 - accuracy: 0.8490\n",
            "Epoch 101/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.3666 - accuracy: 0.8464\n",
            "Epoch 102/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3084 - accuracy: 0.8776\n",
            "Epoch 103/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.3208 - accuracy: 0.8568\n",
            "Epoch 104/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.3063 - accuracy: 0.8685\n",
            "Epoch 105/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.8672\n",
            "Epoch 106/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2809 - accuracy: 0.8919\n",
            "Epoch 107/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3187 - accuracy: 0.8620\n",
            "Epoch 108/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.3095 - accuracy: 0.8724\n",
            "Epoch 109/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2798 - accuracy: 0.8880\n",
            "Epoch 110/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2908 - accuracy: 0.8672\n",
            "Epoch 111/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.3163 - accuracy: 0.8750\n",
            "Epoch 112/200\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.2994 - accuracy: 0.8685\n",
            "Epoch 113/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2745 - accuracy: 0.8776\n",
            "Epoch 114/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2810 - accuracy: 0.8763\n",
            "Epoch 115/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2688 - accuracy: 0.8893\n",
            "Epoch 116/200\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.2866 - accuracy: 0.8789\n",
            "Epoch 117/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2890 - accuracy: 0.8763\n",
            "Epoch 118/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2624 - accuracy: 0.8932\n",
            "Epoch 119/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2620 - accuracy: 0.8932\n",
            "Epoch 120/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3611 - accuracy: 0.8385\n",
            "Epoch 121/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2876 - accuracy: 0.8841\n",
            "Epoch 122/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2756 - accuracy: 0.8737\n",
            "Epoch 123/200\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.2843 - accuracy: 0.8828\n",
            "Epoch 124/200\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.3002 - accuracy: 0.8737\n",
            "Epoch 125/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2650 - accuracy: 0.8880\n",
            "Epoch 126/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2719 - accuracy: 0.8802\n",
            "Epoch 127/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2847 - accuracy: 0.8893\n",
            "Epoch 128/200\n",
            "24/24 [==============================] - 1s 22ms/step - loss: 0.3394 - accuracy: 0.8568\n",
            "Epoch 129/200\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.2948 - accuracy: 0.8789\n",
            "Epoch 130/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2563 - accuracy: 0.8919\n",
            "Epoch 131/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2572 - accuracy: 0.8867\n",
            "Epoch 132/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2529 - accuracy: 0.9023\n",
            "Epoch 133/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2705 - accuracy: 0.8815\n",
            "Epoch 134/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2253 - accuracy: 0.9010\n",
            "Epoch 135/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2421 - accuracy: 0.8893\n",
            "Epoch 136/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2415 - accuracy: 0.8776\n",
            "Epoch 137/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2329 - accuracy: 0.8919\n",
            "Epoch 138/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2489 - accuracy: 0.8893\n",
            "Epoch 139/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3018 - accuracy: 0.8542\n",
            "Epoch 140/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2915 - accuracy: 0.8594\n",
            "Epoch 141/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.2597 - accuracy: 0.8828\n",
            "Epoch 142/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2297 - accuracy: 0.8958\n",
            "Epoch 143/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2197 - accuracy: 0.9023\n",
            "Epoch 144/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2274 - accuracy: 0.9010\n",
            "Epoch 145/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2780 - accuracy: 0.8789\n",
            "Epoch 146/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2686 - accuracy: 0.8776\n",
            "Epoch 147/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.3274 - accuracy: 0.8451\n",
            "Epoch 148/200\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.2363 - accuracy: 0.9076\n",
            "Epoch 149/200\n",
            "24/24 [==============================] - 1s 27ms/step - loss: 0.2505 - accuracy: 0.8828\n",
            "Epoch 150/200\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.2508 - accuracy: 0.8971\n",
            "Epoch 151/200\n",
            "24/24 [==============================] - 0s 21ms/step - loss: 0.2340 - accuracy: 0.8984\n",
            "Epoch 152/200\n",
            "24/24 [==============================] - 1s 21ms/step - loss: 0.2439 - accuracy: 0.8945\n",
            "Epoch 153/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1972 - accuracy: 0.9167\n",
            "Epoch 154/200\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.2145 - accuracy: 0.9062\n",
            "Epoch 155/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.2111 - accuracy: 0.9036\n",
            "Epoch 156/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.1931 - accuracy: 0.9258\n",
            "Epoch 157/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1820 - accuracy: 0.9310\n",
            "Epoch 158/200\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.1779 - accuracy: 0.9258\n",
            "Epoch 159/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1936 - accuracy: 0.9219\n",
            "Epoch 160/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2572 - accuracy: 0.8828\n",
            "Epoch 161/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2223 - accuracy: 0.9023\n",
            "Epoch 162/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2210 - accuracy: 0.9076\n",
            "Epoch 163/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.2465 - accuracy: 0.8880\n",
            "Epoch 164/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2506 - accuracy: 0.8932\n",
            "Epoch 165/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.2088 - accuracy: 0.9062\n",
            "Epoch 166/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.1801 - accuracy: 0.9180\n",
            "Epoch 167/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.1712 - accuracy: 0.9336\n",
            "Epoch 168/200\n",
            "24/24 [==============================] - 0s 17ms/step - loss: 0.1833 - accuracy: 0.9206\n",
            "Epoch 169/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1808 - accuracy: 0.9154\n",
            "Epoch 170/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.2092 - accuracy: 0.9154\n",
            "Epoch 171/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.1670 - accuracy: 0.9245\n",
            "Epoch 172/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.1648 - accuracy: 0.9336\n",
            "Epoch 173/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1596 - accuracy: 0.9375\n",
            "Epoch 174/200\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.1771 - accuracy: 0.9310\n",
            "Epoch 175/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.1587 - accuracy: 0.9362\n",
            "Epoch 176/200\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.1550 - accuracy: 0.9362\n",
            "Epoch 177/200\n",
            "24/24 [==============================] - 0s 18ms/step - loss: 0.1719 - accuracy: 0.9310\n",
            "Epoch 178/200\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.2066 - accuracy: 0.9115\n",
            "Epoch 179/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1379 - accuracy: 0.9414\n",
            "Epoch 180/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1374 - accuracy: 0.9388\n",
            "Epoch 181/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.2061 - accuracy: 0.9128\n",
            "Epoch 182/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.2157 - accuracy: 0.9102\n",
            "Epoch 183/200\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1576 - accuracy: 0.9271\n",
            "Epoch 184/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1341 - accuracy: 0.9388\n",
            "Epoch 185/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.1774 - accuracy: 0.9245\n",
            "Epoch 186/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2503 - accuracy: 0.8711\n",
            "Epoch 187/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1790 - accuracy: 0.9141\n",
            "Epoch 188/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.1869 - accuracy: 0.9193\n",
            "Epoch 189/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1273 - accuracy: 0.9466\n",
            "Epoch 190/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1352 - accuracy: 0.9440\n",
            "Epoch 191/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1403 - accuracy: 0.9362\n",
            "Epoch 192/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.1537 - accuracy: 0.9362\n",
            "Epoch 193/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.2025 - accuracy: 0.9180\n",
            "Epoch 194/200\n",
            "24/24 [==============================] - 0s 14ms/step - loss: 0.1497 - accuracy: 0.9414\n",
            "Epoch 195/200\n",
            "24/24 [==============================] - 0s 15ms/step - loss: 0.1363 - accuracy: 0.9427\n",
            "Epoch 196/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.1336 - accuracy: 0.9401\n",
            "Epoch 197/200\n",
            "24/24 [==============================] - 0s 16ms/step - loss: 0.1182 - accuracy: 0.9427\n",
            "Epoch 198/200\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.1264 - accuracy: 0.9505\n",
            "Epoch 199/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1308 - accuracy: 0.9440\n",
            "Epoch 200/200\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.1009 - accuracy: 0.9583\n",
            "9/9 [==============================] - 0s 3ms/step\n",
            "[[9.47239637e-01]\n",
            " [9.99993622e-01]\n",
            " [1.13484112e-03]\n",
            " [8.94922316e-01]\n",
            " [1.94757245e-04]\n",
            " [9.99767601e-01]\n",
            " [1.22504635e-02]\n",
            " [1.33252461e-05]\n",
            " [9.53755498e-01]\n",
            " [1.00978755e-13]\n",
            " [9.63764429e-01]\n",
            " [2.68141332e-04]\n",
            " [9.87708986e-01]\n",
            " [1.00000000e+00]\n",
            " [5.50311547e-08]\n",
            " [7.47198522e-01]\n",
            " [3.61110824e-06]\n",
            " [1.00000000e+00]\n",
            " [1.00000000e+00]\n",
            " [1.02669201e-05]\n",
            " [3.69945854e-01]\n",
            " [3.44955450e-04]\n",
            " [1.15907356e-01]\n",
            " [6.15687554e-08]\n",
            " [3.69945854e-01]\n",
            " [1.00000000e+00]\n",
            " [9.61118579e-01]\n",
            " [9.99211311e-01]\n",
            " [3.80260907e-08]\n",
            " [4.13883567e-01]\n",
            " [5.98832332e-02]\n",
            " [5.87724149e-01]\n",
            " [2.48613041e-02]\n",
            " [9.99993622e-01]\n",
            " [9.69123423e-01]\n",
            " [8.91530395e-01]\n",
            " [3.69945854e-01]\n",
            " [6.27164364e-01]\n",
            " [9.88821328e-01]\n",
            " [9.95557845e-01]\n",
            " [1.33252461e-05]\n",
            " [2.63915485e-08]\n",
            " [8.12820911e-01]\n",
            " [1.15907356e-01]\n",
            " [2.57882994e-12]\n",
            " [1.84231508e-15]\n",
            " [4.29784501e-04]\n",
            " [2.29909492e-04]\n",
            " [2.98849703e-03]\n",
            " [4.55048144e-01]\n",
            " [3.87930036e-01]\n",
            " [7.50074918e-08]\n",
            " [4.75841239e-02]\n",
            " [5.39300626e-14]\n",
            " [9.61118579e-01]\n",
            " [9.88821328e-01]\n",
            " [3.40215547e-06]\n",
            " [8.00570651e-11]\n",
            " [1.55862913e-01]\n",
            " [9.99864280e-01]\n",
            " [9.69119847e-01]\n",
            " [9.99467134e-01]\n",
            " [3.80260161e-08]\n",
            " [4.55048144e-01]\n",
            " [2.98306666e-04]\n",
            " [1.85309412e-09]\n",
            " [1.00000000e+00]\n",
            " [1.12083368e-01]\n",
            " [1.84231508e-15]\n",
            " [9.96904075e-01]\n",
            " [2.24087425e-02]\n",
            " [3.80260907e-08]\n",
            " [6.31223229e-05]\n",
            " [9.66523707e-01]\n",
            " [9.59858835e-01]\n",
            " [4.01879191e-01]\n",
            " [1.22504635e-02]\n",
            " [9.94114816e-05]\n",
            " [3.68305653e-01]\n",
            " [9.35184777e-01]\n",
            " [1.66918256e-03]\n",
            " [3.88992767e-08]\n",
            " [3.45223671e-05]\n",
            " [8.48366710e-09]\n",
            " [9.99691546e-01]\n",
            " [2.26035723e-08]\n",
            " [9.63764429e-01]\n",
            " [1.93172764e-06]\n",
            " [1.66918256e-03]\n",
            " [4.13883567e-01]\n",
            " [5.62788136e-02]\n",
            " [1.02669201e-05]\n",
            " [1.00000000e+00]\n",
            " [9.28635716e-01]\n",
            " [9.85526145e-01]\n",
            " [6.46306455e-01]\n",
            " [1.12083368e-01]\n",
            " [7.72803469e-05]\n",
            " [6.34253866e-14]\n",
            " [7.88369798e-05]\n",
            " [1.00000000e+00]\n",
            " [1.50264919e-01]\n",
            " [4.52245563e-01]\n",
            " [9.13739622e-01]\n",
            " [6.83228478e-08]\n",
            " [9.99947011e-01]\n",
            " [8.00570651e-11]\n",
            " [9.99909759e-01]\n",
            " [1.32057467e-03]\n",
            " [9.98486638e-01]\n",
            " [1.55862913e-01]\n",
            " [9.98486638e-01]\n",
            " [9.99961257e-01]\n",
            " [5.16212196e-04]\n",
            " [9.99460399e-01]\n",
            " [9.99951899e-01]\n",
            " [3.67222399e-01]\n",
            " [9.41671133e-01]\n",
            " [9.81884003e-01]\n",
            " [1.40120699e-06]\n",
            " [9.97821450e-01]\n",
            " [8.78902793e-01]\n",
            " [3.37500907e-08]\n",
            " [1.37242945e-02]\n",
            " [9.73012567e-01]\n",
            " [6.15687554e-08]\n",
            " [9.87279952e-01]\n",
            " [1.70738026e-01]\n",
            " [2.24087425e-02]\n",
            " [9.53014851e-01]\n",
            " [5.87723970e-01]\n",
            " [6.34253866e-14]\n",
            " [9.99810159e-01]\n",
            " [1.00000000e+00]\n",
            " [4.58272069e-08]\n",
            " [1.00000000e+00]\n",
            " [2.08164238e-07]\n",
            " [8.78902793e-01]\n",
            " [1.00000000e+00]\n",
            " [3.67222399e-01]\n",
            " [9.51891243e-01]\n",
            " [9.75523949e-01]\n",
            " [9.95541930e-01]\n",
            " [2.89518297e-01]\n",
            " [9.14823711e-01]\n",
            " [9.99206126e-01]\n",
            " [3.87930036e-01]\n",
            " [9.64495361e-01]\n",
            " [4.63693738e-02]\n",
            " [1.69380507e-06]\n",
            " [2.48613041e-02]\n",
            " [1.84231508e-15]\n",
            " [7.79255390e-01]\n",
            " [9.51891243e-01]\n",
            " [6.04630485e-02]\n",
            " [1.24946004e-04]\n",
            " [3.63594025e-01]\n",
            " [9.53014851e-01]\n",
            " [6.74107881e-08]\n",
            " [2.63916480e-08]\n",
            " [8.12820911e-01]\n",
            " [9.99995172e-01]\n",
            " [1.50264919e-01]\n",
            " [1.50264919e-01]\n",
            " [8.93704116e-01]\n",
            " [7.94232309e-01]\n",
            " [4.69571787e-05]\n",
            " [4.50467604e-04]\n",
            " [5.55747747e-01]\n",
            " [9.64495361e-01]\n",
            " [6.31223229e-05]\n",
            " [9.12409306e-01]\n",
            " [9.99998212e-01]\n",
            " [2.31936175e-25]\n",
            " [7.47926652e-01]\n",
            " [9.99993622e-01]\n",
            " [1.00000000e+00]\n",
            " [2.68526455e-12]\n",
            " [4.52245563e-01]\n",
            " [9.69255686e-01]\n",
            " [9.99987066e-01]\n",
            " [8.58206647e-07]\n",
            " [9.78394508e-01]\n",
            " [4.75841239e-02]\n",
            " [8.54532778e-01]\n",
            " [9.81884003e-01]\n",
            " [9.69123423e-01]\n",
            " [1.55862913e-01]\n",
            " [7.35601187e-01]\n",
            " [9.99937773e-01]\n",
            " [9.96341050e-01]\n",
            " [3.68305415e-01]\n",
            " [1.10462001e-02]\n",
            " [4.75841239e-02]\n",
            " [8.00570651e-11]\n",
            " [9.61401641e-01]\n",
            " [5.36977649e-01]\n",
            " [7.91881973e-08]\n",
            " [9.99976695e-01]\n",
            " [9.95131552e-01]\n",
            " [8.29549432e-01]\n",
            " [9.88369346e-01]\n",
            " [9.95131552e-01]\n",
            " [8.14081358e-10]\n",
            " [1.90640776e-03]\n",
            " [2.76578830e-05]\n",
            " [4.11381155e-01]\n",
            " [5.85225463e-01]\n",
            " [1.96700782e-01]\n",
            " [8.78902793e-01]\n",
            " [9.88369346e-01]\n",
            " [9.54788120e-05]\n",
            " [1.00000000e+00]\n",
            " [5.62788136e-02]\n",
            " [1.24946004e-04]\n",
            " [7.28301802e-06]\n",
            " [1.60621524e-01]\n",
            " [4.69571787e-05]\n",
            " [8.45040858e-01]\n",
            " [4.58272069e-08]\n",
            " [8.16080749e-01]\n",
            " [3.45223671e-05]\n",
            " [7.88366815e-05]\n",
            " [9.96800065e-01]\n",
            " [9.73832369e-01]\n",
            " [8.69466007e-01]\n",
            " [9.41671133e-01]\n",
            " [8.84358644e-01]\n",
            " [2.68141332e-04]\n",
            " [9.97821450e-01]\n",
            " [1.10462001e-02]\n",
            " [3.27119678e-02]\n",
            " [3.74063522e-01]\n",
            " [3.63594025e-01]\n",
            " [1.69380507e-06]\n",
            " [1.22504635e-02]\n",
            " [9.63943545e-04]\n",
            " [2.50335853e-03]\n",
            " [8.75689328e-01]\n",
            " [5.60326371e-05]\n",
            " [1.98987484e-01]\n",
            " [1.70224518e-01]\n",
            " [1.00000000e+00]\n",
            " [1.00436609e-03]\n",
            " [1.60192803e-03]\n",
            " [9.99909759e-01]\n",
            " [1.51327960e-02]\n",
            " [1.00000000e+00]\n",
            " [9.99892473e-01]\n",
            " [3.34552466e-03]\n",
            " [9.66523707e-01]\n",
            " [1.00978755e-13]\n",
            " [3.62392813e-01]\n",
            " [2.68526455e-12]\n",
            " [1.37242945e-02]\n",
            " [9.99999881e-01]\n",
            " [1.95493817e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MACHINE LEARNING:\n",
        "\n"
      ],
      "metadata": {
        "id": "RqvZGv-cNkMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**DECISION TREE:**\n"
      ],
      "metadata": {
        "id": "lmV_kXyUNrQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Split the data into features (x) and target labels (y)\n",
        "x = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create and train the Decision Tree Classifier\n",
        "classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# You can also print the classification report for more detailed evaluation\n",
        "report = classification_report(y_test, y_pred)\n",
        "print('Classification Report:\\n', report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b9JqNhjNaCv",
        "outputId": "153debb0-b380-41da-d14f-2d5dbcad8291"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        98\n",
            "           1       1.00      1.00      1.00       107\n",
            "\n",
            "    accuracy                           1.00       205\n",
            "   macro avg       1.00      1.00      1.00       205\n",
            "weighted avg       1.00      1.00      1.00       205\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM FOREST**"
      ],
      "metadata": {
        "id": "XDzYeWjEeWtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create a RandomForestRegressor\n",
        "RandomForestRegModel = RandomForestRegressor()\n",
        "RandomForestRegModel.fit(X_train, y_train)\n",
        "\n",
        "# Make regression predictions on the test set\n",
        "y_pred = RandomForestRegModel.predict(X_test)\n",
        "print(y_pred)\n",
        "# Define a threshold for considering a prediction as accurate (you can adjust this threshold)\n",
        "accuracy_threshold = 0.5\n",
        "\n",
        "# Calculate the accuracy based on the threshold\n",
        "accurate_predictions = np.abs(y_pred - y_test) <= accuracy_threshold\n",
        "accuracy = np.mean(accurate_predictions) * 100.0\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "labF2wwJjoqJ",
        "outputId": "83b42067-1581-44d5-9bee-7eb20c627508"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.   0.14 0.   1.   0.   0.01 0.   0.   0.   0.   0.02 0.   0.95 0.13\n",
            " 1.   0.9  1.   0.01 0.99 0.01 1.   0.98 0.93 0.98 0.9  1.   0.99 0.02\n",
            " 1.   0.86 0.99 0.   0.01 0.99 0.04 0.   0.15 0.   0.85 1.   0.07 0.99\n",
            " 1.   1.   1.   0.98 0.98 0.05 0.   0.1  0.02 0.   0.94 0.04 0.01 0.\n",
            " 0.   0.91 0.02 0.14 0.   0.02 0.99 0.04 0.13 0.   0.   0.98 0.92 0.99\n",
            " 0.9  1.   1.   0.   0.05 0.02 0.12 0.81 0.02 0.   0.   0.04 0.99 0.13\n",
            " 0.98 0.   0.99 0.   1.   0.   0.01 0.   1.   0.95 0.96 0.   0.04 0.\n",
            " 1.   1.   0.92 0.96 0.99 0.07 0.01 0.98 0.   0.92 0.02 0.99 0.95 0.07\n",
            " 1.   0.07 0.98 0.01 0.92 0.01 0.   0.96 0.05 0.85 1.   0.   0.02 1.\n",
            " 1.   0.9  0.98 0.01 0.   0.01 1.   1.   0.89 0.03 0.   0.99 0.   0.98\n",
            " 0.97 0.02 0.96 0.02 0.15 1.   0.97 0.95 0.91 0.02 0.9  0.91 0.94 0.02\n",
            " 0.04 0.   0.98 0.93 0.   0.01 0.02 1.   0.98 0.01 0.87 0.97 0.99 1.\n",
            " 0.86 1.   1.   0.96 0.99 0.91 0.97 1.   0.09 1.   1.   0.01 0.   0.9\n",
            " 0.   0.04 0.98 0.02 0.76 0.01 0.97 0.   0.03 0.99 0.1  0.99 0.   0.97\n",
            " 0.76 0.98 0.13 0.   1.   0.99 1.   0.01 0.98]\n",
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVM**"
      ],
      "metadata": {
        "id": "CrmQ1vcPi3QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Select features and target variable\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create an SVM classifier with a linear kernel\n",
        "classifier = SVC(kernel='linear', random_state=0)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_eC-nghismF",
        "outputId": "cb555a5c-9c44-445e-b614-27c90ab9acca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Select features and target variable\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
        "\n",
        "# Create an SVM classifier with a linear kernel\n",
        "classifier = SVC(kernel='linear', random_state=0)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkap8D7v6fEr",
        "outputId": "5ad67211-c47b-4a0d-bf24-ab8a15dc4cae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "PNFO5TVyjzPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report  # Import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/AgileSW&DevOps/heart.csv')\n",
        "\n",
        "# Select features and target variable\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)\n",
        "\n",
        "# Standardize the feature values\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Create a Logistic Regression classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(y_pred)\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weTikZX_60XT",
        "outputId": "4d8d22c6-1de2-46c2-f87a-ff383ea2c3c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0\n",
            " 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 1\n",
            " 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1\n",
            " 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 0\n",
            " 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0]\n",
            "Accuracy: 0.8521400778210116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.77      0.84       131\n",
            "           1       0.80      0.94      0.86       126\n",
            "\n",
            "    accuracy                           0.85       257\n",
            "   macro avg       0.86      0.85      0.85       257\n",
            "weighted avg       0.86      0.85      0.85       257\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report  # Import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/AgileSW&DevOps/heart.csv')\n",
        "\n",
        "# Select features and target variable\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Standardize the feature values\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Create a Logistic Regression classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(y_pred)\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvAM8Vktj8yg",
        "outputId": "d5f79772-721b-4a6d-f568-3fcdd9fe82ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0\n",
            " 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1\n",
            " 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 1 1 1 0\n",
            " 1 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1\n",
            " 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 1\n",
            " 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 0 1]\n",
            "Accuracy: 0.8638132295719845\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.80      0.85       123\n",
            "           1       0.83      0.93      0.88       134\n",
            "\n",
            "    accuracy                           0.86       257\n",
            "   macro avg       0.87      0.86      0.86       257\n",
            "weighted avg       0.87      0.86      0.86       257\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**\n"
      ],
      "metadata": {
        "id": "iD69Jlelns92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create a KNN classifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecXSWj0-5klz",
        "outputId": "fc2583c6-b9ba-4efb-ee1d-87e0be5650bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create a KNN classifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=10, metric='minkowski', p=2)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK0A1HxwmrjT",
        "outputId": "870b394a-a694-4e07-c42b-6df706acd04a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create a KNN classifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=2, metric='minkowski', p=2)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsK7R7Vj5p1L",
        "outputId": "95d159ce-de3e-4f81-e4e2-9d0576e5dd6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAIVE BAYES**\n"
      ],
      "metadata": {
        "id": "5VjvQiPdo1vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "x = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Create a Gaussian Naive Bayes classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD5-tRM2ohG5",
        "outputId": "c31fd473-a943-4bb5-8156-256d78a27599"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1\n",
            " 1 1 1 0 0 1 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 1 1\n",
            " 1 1 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 1 1 1 1\n",
            " 1 1 0 1 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1\n",
            " 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 1 0\n",
            " 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0]\n",
            "Accuracy: 0.7937743190661478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the heart dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AgileSW&DevOps/heart.csv\")\n",
        "\n",
        "# Select features (X) and target variable (y)\n",
        "x = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=32)\n",
        "\n",
        "# Create a Gaussian Naive Bayes classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDHmnL_D6GIe",
        "outputId": "9c25d773-202a-41db-a2ca-effef732f499"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0\n",
            " 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n",
            " 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0\n",
            " 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0]\n",
            "Accuracy: 0.8443579766536965\n"
          ]
        }
      ]
    }
  ]
}